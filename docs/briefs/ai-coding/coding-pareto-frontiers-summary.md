---
title: "Executive Summary: The Three Pareto Frontiers in AI Coding"
date: 2026-02-23
author: "Gabor Melli"
type: executive-summary
canonical: coding-pareto-frontiers.md
---

# Executive Summary: The Three Pareto Frontiers in AI Coding

**Based on**: 16 sources including METR RCT, ICLR 2025, DORA 2025, Stanford HAI

---

## The Problem

AI coding tools promise speed. The evidence shows they deliver speed — but at the cost of quality, review burden, and downstream defects. Six independent studies converge on the same finding.

## Three Frontiers, One Insight

1. **Model Selection** (well-mapped): No single model wins all benchmarks. Claude Opus leads SWE-bench (80.9%), Gemini leads LiveCodeBench (91.7%), DeepSeek offers 73% accuracy at 1/170th the cost. Cascade routing (ICLR 2025) can save 50x in costs.

2. **Workflow Design** (poorly mapped — largest gap): The "AI speed trap" is documented by 6 studies: perceived +20% speed gains mask -19% actual throughput (METR RCT), +41% bug rates (Uplevel), and +91% review time (DORA). The quality-first AI configuration has never been studied.

3. **Organizational Productivity** (emerging): Connects to the broader AI productivity paradox — more AI adoption correlates with *less* delivery stability (-7.2% per 25% adoption, DORA 2025).

## Key Takeaway

**Invest in workflow engineering before model procurement.** Agentic wrappers (+16.5 percentage points on Aider) deliver larger gains than switching to more expensive models. The unmapped quality-first quadrant is the highest-value research target.

## Confidence

High for evidence synthesis, Medium for predictive claims. Would change if quality-optimized AI workflow studies are published.

---

*[Read the full brief](coding-pareto-frontiers.md) for complete data tables, source analysis, and methodology.*
